{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e467dec",
   "metadata": {},
   "source": [
    "# Basic examples\n",
    "\n",
    "In this notebook we will show main **mpytools** utilities. You need to have installed **mpytools** with:\n",
    "\n",
    "python -m pip install git+https://github.com/cosmodesi/mpytools\n",
    "\n",
    "Everything presented here is MPI'ed, i.e. memory and computation can be split among multiple processes\n",
    "(e.g. ``mpiexec -np 10 python yourscript.py`` or ``srun -n 10 yourscript.py``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53b591ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import mpytools as mpy\n",
    "from mpytools import Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b218fbf0",
   "metadata": {},
   "source": [
    "## Array\n",
    "Let's create some MPI-scattered array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7239e6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_array = np.ones((10, 2), dtype='f8')\n",
    "array = mpy.array(local_array)  # local_array on each process\n",
    "# One can also start with a global array:\n",
    "mpicomm = mpy.COMM_WORLD\n",
    "global_array = np.ones((100, 2), dtype='f8') if mpicomm.rank == 0 else None\n",
    "array = mpy.array(global_array, mpicomm=mpicomm, mpiroot=0)\n",
    "# Alternatively, one can directly create an empty array,\n",
    "# full of 0, 1, any value using empty, zeros, ones, full, respectively; e.g.:\n",
    "zeros = mpy.zeros((10, 2))  # array of shape (10, 2) on each rank\n",
    "# Alternatively, one can provide the global shape instead:\n",
    "empty = mpy.empty(cshape=(100, 2))\n",
    "assert empty.cshape == (100, 2)\n",
    "assert empty.csize == 200  # csize is the collective array size; to get the local array size: empty.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e486ce",
   "metadata": {},
   "source": [
    "### Concatenating\n",
    "\n",
    "Arrays can be concatenated locally, or collectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772523b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local concatenation, e.g. on first rank we will have the beginning of all three input arrays\n",
    "# this is not costly as no data is exchanged between various ranks\n",
    "test = np.concatenate([zeros, empty])\n",
    "# If one wants to preserve the global order, one should rather do (notice the starting 'c' meaning 'collective'):\n",
    "test = mpy.cconcatenate([zeros, empty])\n",
    "# This requires data to be passed between all processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee6b10c",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "Arrays can be sliced locally, or collectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4a830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local slice, i.e. impacts each process independently\n",
    "test2 = test[2:80]  # or test[slice(2, 80)]\n",
    "# Collective slice, i.e. slice the array globally (including load balancing on all processes)\n",
    "test2 = test.cslice(60)\n",
    "assert test2.cshape[0] == 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a8dee",
   "metadata": {},
   "source": [
    "### Miscellaneous\n",
    "Note that *any* numpy function will apply to mpy.array. Main collective operations are also implemented (csum, cstd, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d583e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One can apply any numpy function (locally) to a mpyarray\n",
    "mean = np.mean(array)  # local mean\n",
    "cmean = mpy.cmean(array)  # collective mean\n",
    "# As in numpy, a few functions are attached as methods to mpy.array, e.g.:\n",
    "mean = array.mean()  # local mean\n",
    "cmean = array.cmean()  # collective mean\n",
    "# Same for csum, cvar, cstd, cmin, cmax..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fecd03b",
   "metadata": {},
   "source": [
    "## Catalog\n",
    "Let's create some catalog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38799855",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "rng = mpy.random.MPIRandomState(size, seed=42)  # invariant under number of processes\n",
    "catalog = Catalog(data={'RA': rng.uniform(0., 20.), 'DEC': rng.uniform(-10., 10.),\n",
    "                        'Z': rng.uniform(1., 2.), 'Position': rng.uniform(0., 1., itemshape=3)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750cd60",
   "metadata": {},
   "source": [
    "### Column access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf940290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can be accessed locally through:\n",
    "ra = catalog['RA']  # or catalog.get('RA')\n",
    "# This returns a mpy.array, so one can do:\n",
    "ra.cmean()\n",
    "# To get a standard numpy array one can do:\n",
    "ra = catalog.get('RA', return_type='nparray')\n",
    "# The full column (concatenated across all ranks) can be accessed through:\n",
    "ra = catalog.cget('RA')\n",
    "# Alternatively, ra = catalog['RA'].gather()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf079c6",
   "metadata": {},
   "source": [
    "### I/Os\n",
    "Catalogs can be written/read from many formats: 'fits', 'hdf5', 'npy', 'bigfile', 'asdf'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c193bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog columns are ['RA', 'DEC', 'Z', 'Position']\n",
      "Catalog columns currently read are dict_keys(['RA'])\n"
     ]
    }
   ],
   "source": [
    "tmp_dir = '_tests'\n",
    "\n",
    "fn = os.path.join(tmp_dir, 'tmp.fits')  # same for hdf5, npy, bigfile, asdf\n",
    "catalog.write(fn)\n",
    "test = Catalog.read(fn)  # you can provide optional arguments, e.g. \"ext\" for fits --- see mpytools.io.FitsFile\n",
    "assert test == catalog  # check catalog equality\n",
    "\n",
    "fns = [os.path.join(tmp_dir, 'tmp1.fits'), os.path.join(tmp_dir, 'tmp2.fits')]\n",
    "test.write(fns)  # one can split in many catalogs\n",
    "test = Catalog.read(fns)  # read multiple catalogs at the same time\n",
    "# Note that .read() only reads file headers, so is almost free\n",
    "# columns are only read when accessing them, e.g.:\n",
    "test['RA'][:10]  # this is a mpyarray, so one can use all methods mentioned above\n",
    "print('Catalog columns are', test.columns())\n",
    "print('Catalog columns currently read are', test.data.keys())\n",
    "\n",
    "# One can even write to / read from different file types (using default options for each file type)\n",
    "fns = [os.path.join(tmp_dir, 'tmp1.fits'), os.path.join(tmp_dir, 'tmp2.hdf5')]\n",
    "test.write(fns)\n",
    "test = Catalog.read(fns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9936e",
   "metadata": {},
   "source": [
    "### Concatenating\n",
    "Catalogs can be concatenated locally, or collectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a1aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local concatenation, e.g. on first rank we will have the beginning of all three input catalogs\n",
    "# this is not costly as no data is exchanged between various ranks\n",
    "# Again, columns that are not read yet will be concatenated when accessing them.\n",
    "test3 = Catalog.concatenate(test, test, test)\n",
    "# If one wants to preserve the global order, one should rather do (notice the starting 'c' meaning 'collective'):\n",
    "test3 = Catalog.cconcatenate(test, test, test)\n",
    "# This requires data to be passed between all processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4876302",
   "metadata": {},
   "source": [
    "### Slicing\n",
    "Catalogs can be sliced locally, or collectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8880264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local slice, i.e. impacts each process independently\n",
    "test2 = test[2:80]  # or test.slice(2, 80), or test[np.arange(2, 80)]\n",
    "# Collective slice, i.e. resize the catalog globally (including load balancing on all processes)\n",
    "test2 = test.cslice(60)\n",
    "assert test2.csize == 60  # csize is the collective catalog size; to get the local catalog size: test2.size\n",
    "# Internally, this will slice column 'RA' (which has already been read above)\n",
    "# but has virtually no cost for columns that have not been read yet:\n",
    "# slicing will be applied when accessing them, e.g.:\n",
    "assert test2['Position'].cshape[0] == 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b1e770",
   "metadata": {},
   "source": [
    "### Miscellaneous\n",
    "Other helpful routines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a134a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catalog columns are ['RA', 'DEC', 'Z', 'Position', 'zeros', 'trues']\n",
      "Catalog columns starting with \"t\" are ['trues']\n",
      "Catalog columns, except \"RA\" now are ['DEC', 'Z', 'Position', 'zeros']\n"
     ]
    }
   ],
   "source": [
    "# Get (collective) indices\n",
    "cindices = catalog.cindices()\n",
    "assert np.all(cindices.gather(mpiroot=None) == np.arange(catalog.csize))\n",
    "# Get column of zeros of shape (catalog.size, 3)\n",
    "catalog['zeros'] = catalog.zeros(itemshape=3)\n",
    "# Same for empty, ones, falses, trues, nans, full\n",
    "catalog['trues'] = catalog.trues()\n",
    "print('Catalog columns are', catalog.columns())\n",
    "print('Catalog columns starting with \"t\" are', catalog.columns(include='t*'))\n",
    "del catalog['trues']\n",
    "print('Catalog columns, except \"RA\" now are', catalog.columns(exclude='RA'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
